title: 线性模型
categories:
  - 机器学习
tags:
  - 线性回归
  - 对数几率回归
date: 2018-10-11 20:10:07
---
# 1.基本形式 #
给定有d个属性描述的示例\\(x=(x_1:x_2……x_d)\\),其中Xi是x在第i个属性上的取值，线性模型试图学得一个通过属性的线性组合来进行预测的函数，即
$$ f(x)=w_1x_1+w_2x_2+……+w_dx_d+b $$
一般向量形式写成
$$ f(x)=w^Tx+b $$
# 2.线性回归 #
我们先考一种最简单的情况，x只有一种属性，即假设函数为
$$ f(x_i)=wx_i+b $$
选择均方误差作为性能度量，试图使方差最下，即
$$ (w^*,b^*)=arg min(w,b)=\Sigma^m_{i=1}(f(x_i)-y_i)^2 $$
$$ =arg min(w,b)\Sigma^m_{i=1}(y_i-wx_i-b)^2 $$ 
基于均方误差进行模型求解的方法称为最小二乘法，我们将损失函数分别对w和b求导得
<a href="#ercheng" ><font color=red>接下来点击这里</font></a>

# 3.对数几率回归 #
我们使用sigmod函数作为“广义线性模型”的单调可微函数g（.），得到
$$ y=\frac {1}{1+e^{-(w^T x+b)}} \qquad (1)$$
上式可变换为
$$ ln \frac{y}{1-y}=w^Tx+b \qquad (2) $$
若将y视为样本x作为正例的可能性，则1-y是其反例的可能性。两者的比值\\( \frac{y}{1-y} \\)称为几率，反映了x作为正例的相对可能性，对几率去对数得到对数几率
$$ ln \frac {y}{1-y}    $$ 

由（2）式可知，实际上是用线性回归模型的预测结果去逼近真是标记的对数几率，其模型称为“**对数几率回归**”

我们来看如何求w和b，我们把（1）式的y视为类后验概率估计p(y=1|x)，在（2）式重写为

$$ ln \frac {p(y=1|x)}{p(y=0|x)} =w^Tx+b $$

显然有
$$ p(y=1|x)=\frac{e^{w^T x+b}}{1+e^{w^T x+b}} $$
$$ p(y=0|x)=\frac{1}{1+e^{w^T x+b}} $$
对于给定的数据集\\( {(x\_i,y\_i)}^N\_{i=1},y \in {0,1} \\),可以应用极大似然估计估计模型参数，从而得到逻辑回归模型
设P(Y=1|x)=g(x),P(Y=0|x)=1-g(x)
似然函数为
$$ \prod^N_{i=1} [g(x_i)]^y_i [1-g(x_i)]^{1-y_i} $$
对数似然函数为
$$ L(w)=\Sigma ^N_{i=1} [y_ilog(x_i)+(1-y_i)log(1-g(x_i))] $$
$$ =\Sigma^N_{i=1}[y_ilog \frac {g(x_i)}{1-g(x_i)} + log(1-g(x_i))] $$
$$ =\Sigma^N_{i=1}[y_i (w*x_i)-log(1+\exp(w \ast x_i))] $$
对L(w)求最大值，得到w的估计值,常用梯度下降和牛顿法解决





<br/>
<div id='ercheng'/>
 - **西瓜书 54页3.7和3.8推导公式**

<img src="/images/p54.jpg" width=480 align=center/>

 - **西瓜书59页 3.27推导公式**

<img src="/images/p59.jpg" width=480 align=center/>
- **p55 3.10**
<img src="http://pgmz9e1an.bkt.clouddn.com/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20181015204258.jpg" width=480 align=center/>