title: 线性回归
categories:
  - 机器学习
tags:
  - 线性回归
  - 对数几率回归
date: 2018-10-11 20:10:07
---
# 对数几率回归 #
我们使用sigmod函数作为“广义线性模型”的单调可微函数g（.），得到
$$ y=\frac {1}{1+e^{-(w^T x+b)}} \qquad (1)$$
上式可变换为
$$ ln \frac{y}{1-y}=w^Tx+b \qquad (2) $$
若将y视为样本x作为正例的可能性，则1-y是其反例的可能性。两者的比值\\( \frac{y}{1-y} \\)称为几率，反映了x作为正例的相对可能性，对几率去对数得到对数几率
$$ ln \frac {y}{1-y}    $$ 

由（2）式可知，实际上是用线性回归模型的预测结果去逼近真是标记的对数几率，其模型称为“**对数几率回归**”

我们来看如何求w和b，我们把（1）式的y视为类后验概率估计p(y=1|x)，在（2）式重写为

$$ ln \frac {p(y=1|x)}{p(y=0|x)} =w^Tx+b $$

显然有
$$ p(y=1|x)=\frac{e^{w^T x+b}}{1+e^{w^T x+b}} $$
$$ p(y=0|x)=\frac{1}{1+e^{w^T x+b}} $$
对于给定的数据集\\( {(x\_i,y\_i)}^N\_{i=1},y \in {0,1} \\),可以应用极大似然估计估计模型参数，从而得到逻辑回归模型
设P(Y=1|x)=g(x),P(Y=0|x)=1-g(x)
似然函数为
$$ \prod^N_{i=1} [g(x_i)]^y_i [1-g(x_i)]^{1-y_i} $$
对数似然函数为
$$ L(w)=\Sigma ^N_{i=1} [y_ilog(x_i)+(1-y_i)log(1-g(x_i))] $$
$$ =\Sigma^N_{i=1}[y_ilog \frac {g(x_i)}{1-g(x_i)} + log(1-g(x_i))] $$
$$ =\Sigma^N_{i=1}[y_i (w*x_i)-log(1+\exp(w \ast x_i))] $$
对L(w)求最大值，得到w的估计值,常用梯度下降和牛顿法解决





<br/>
 - **西瓜书 54页3.7和3.8推导公式**

<img src="/images/p54.jpg" width=480 align=center/>

 - **西瓜书59页 3.27推导公式**

<img src="/images/p59.jpg" width=480 align=center/>

<img src="http://pgmz9e1an.bkt.clouddn.com/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20181015204258.jpg" width=480 align=center/>