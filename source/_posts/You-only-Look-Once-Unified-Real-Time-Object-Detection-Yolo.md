---
title: 'You only Look Once Unified,Real-Time Object Detection(Yolo)'
date: 2018-12-01 14:26:11
categories:
  - 论文阅读
tags:
---
# 摘要 #
我们提出了YOLO，一种新的目标检测方法。以前的目标检测工作重新利用分类器来执行检测。相反，我们将目标检测框架看作回归问题从空间上分割边界框和相关的类别概率。单个神经网络在一次评估中直接从完整图像上预测边界框和类别概率。由于整个检测流水线是单一网络，因此可以直接对检测性能进行端到端的优化。
# 引言 #
1. YOLO速度非常快。由于我们将检测视为回归问题，所以我们不需要复杂的流程
2. YOLO在进行预测时，会对图像进行全局推理。与基于滑动窗口和区域提出的技术不同，YOLO在训练期间和测试时会看到整个图像，所以它隐式地编码了关于类的上下文信息以及它们的外观。快速R-CNN是一种顶级的检测方法[14]，因为它看不到更大的上下文，所以在图像中会将背景块误检为目标。与快速R-CNN相比，YOLO的背景误检数量少了一半。
3. YOLO学习目标的泛化表示。当在自然图像上进行训练并对艺术作品进行测试时，YOLO大幅优于DPM和R-CNN等顶级检测方法。由于YOLO具有高度泛化能力，因此在应用于新领域或碰到意外的输入时不太可能出故障。

# 统一检测 #
我们的系统将输入图像分成S×S的网格。如果一个目标的中心落入一个网格单元中，该网格单元负责检测该目标。

每个网格单元预测这些盒子的B个边界框和置信度分数c。这些置信度分数反映了该模型对盒子是否包含目标的信心，以及它预测盒子的准确程度。在形式上，我们将置信度定义为\\(Pr(Object)\*IOU^{truth}_{pred}\\)。前者是边界框含有目标的可能性，后者是边界框的准确度。前者记为Pr（Object），如果边界框是背景（不包含目标），则Pr（Object）=0，如果包含目标，Pr（Object）=1。边界框的准确度用预测框和实际框的LOU表示。
边界框的大小与位置可以用4个值来表征： (x, y,w,h) ，其中 (x,y) 是边界框的中心坐标，而 w 和 h 是边界框的宽与高。还有一点要注意，中心坐标的预测值 (x,y) 是相对于每个单元格左上角坐标点的偏移值，并且单位是相对于单元格大小的。而边界框的 w 和 h 预测值是相对于整个图片的宽与高的比例，这样理论上4个元素的大小应该在 [0,1] 范围。这样，每个边界框的预测值实际上包含5个元素： (x,y,w,h,c) ，其中前4个表征边界框的大小与位置，而最后一个值是置信度。
还有分类问题，对于每一个单元格其还要给出预测出 C 个类别概率值，其表征的是由该单元格负责预测的边界框其目标属于各个类别的概率。但是这些概率值其实是在各个边界框置信度下的条件概率，即 \\(Pr(class_i|object)\\) 。值得注意的是，不管一个单元格预测多少个边界框，其只预测一组类别概率值，这是Yolo算法的一个缺点，在后来的改进版本中，Yolo9000是把类别概率预测值与边界框是绑定在一起的。同时，我们可以计算出各个边界框类别置信度（class-specific confidence scores）: 
$$ Pr(class_i|object)×Pr(object)×IOU^{truth}_{pred} = Pr(class_i)× IOU^{truth}_{pred} $$
边界框类别置信度表征的是该边界框中目标属于各个类别的可能性大小以及边界框匹配目标的好坏。后面会说，一般会根据类别置信度来过滤网络的预测框
总结一下，每个单元格需要预测 (B×5+C) 个值。如果将输入图片划分为 S×S 网格，那么最终预测值为 S× S × (B×5+C) 大小的张量。整个模型的预测值结构如下图所示。对于PASCAL VOC数据，其共有20个类别，如果使用 S=7,B=2 ，那么最终的预测结果就是 7× 7× 30 大小的张量。在下面的网络结构中我们会详细讲述每个单元格的预测值的分布位置。
## 网络设计 ##
网络参考googlelenet，有24个卷积层，2个全连接层
<img src="/images/paper/yolo01.jpg"/>
## 训练 ##
在ImageNet上使用前20个卷积层后面加一个平均池化和全连接进行预训练，然后在20层卷积后加上随机初始化的4个卷积层和2个全连接层。
**损失函数分析**
下面是训练损失函数的分析，Yolo算法将目标检测看成回归问题，所以采用的是均方差损失函数。但是对不同的部分采用了不同的权重值。首先区分定位误差和分类误差。对于定位误差，即边界框坐标预测误差，采用较大的权重 \\(\lambda _{coord}=5\\) 。然后其区分不包含目标的边界框与含有目标的边界框的置信度，对于前者，采用较小的权重值\\( \lambda _{noobj}=0.5\\) 。其它权重值均设为1。然后采用均方误差，其同等对待大小不同的边界框，但是实际上较小的边界框的坐标误差应该要比较大的边界框要更敏感。为了保证这一点，将网络的边界框的宽与高预测改为对其平方根的预测，即预测值变为 \\((x,y,\sqrt{w}, \sqrt{h})\\) 。
另外一点时，由于每个单元格预测多个边界框。但是其对应类别只有一个。那么在训练时，如果该单元格内确实存在目标，那么只选择与ground truth的IOU最大的那个边界框来负责预测该目标，而其它边界框认为不存在目标。这样设置的一个结果将会使一个单元格对应的边界框更加专业化，其可以分别适用不同大小，不同高宽比的目标，从而提升模型性能。大家可能会想如果一个单元格内存在多个目标怎么办，其实这时候Yolo算法就只能选择其中一个来训练，这也是Yolo算法的缺点之一。要注意的一点时，对于不存在对应目标的边界框，其误差项就是只有置信度，坐标项误差是没法计算的。而只有当一个单元格内确实存在目标时，才计算分类误差项，否则该项也是无法计算的。(参考吴恩达深度学习目标检测损失函数那里)
<img src="/images/paper/yolo02.jpg"/>
其中第一项是边界框中心坐标的误差项， \\(1^{obj}_{ij}\\) 指的是第 i 个单元格存在目标，且该单元格中的第 j 个边界框负责预测该目标。第二项是边界框的高与宽的误差项。第三项是包含目标的边界框的置信度误差项。第四项是不包含目标的边界框的置信度误差项。而最后一项是包含目标的单元格的分类误差项， \\(1^{obj}_{i}\\) 指的是第 i 个单元格存在目标。这里特别说一下置信度的target值 \\(C_i\\) ，如果是不存在目标，此时由于 Pr(object)=0，那么 \\(C_i=0\\) 。如果存在目标， Pr(object)=1 ，此时需要确定 \\(\text{IOU}^{truth}_{pred}\\) ，当然你希望最好的话，可以将IOU取1，这样\\( C_i=1\\) ，但是在YOLO实现中，使用了一个控制参数rescore（默认为1），当其为1时，IOU不是设置为1，而就是计算truth和pred之间的真实IOU。不过很多复现YOLO的项目还是取\\( C_i=1\\) ，这个差异应该不会太影响结果吧。

参考文献
1：https://zhuanlan.zhihu.com/p/32525231