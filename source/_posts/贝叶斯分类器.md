---
title: 贝叶斯分类器
categories:
  - 机器学习
date: 2018-11-08 15:36:37
tags:
---
# 朴素贝叶斯法 #
## 朴素贝叶斯基本原理 ##
 <img src="/images/bayes1.jpg" width="640"/>
## 朴素贝叶斯基本算法 ##
<img src="/images/bayes2.png" width="640"/>
### 处理连续属性 ###
对连续属性可考虑概率密度函数，假定\\(p(x_i|c)~N(\mu_{c,i},\sigma^2_{c,i})\\),其中\\(\mu_{c,i},\sigma^2_{c,i}\\)分别是第c类样本在第i个属性上取值的均值和平方，则有
$$ p(x_i|c)=\frac{1}{\sqrt{2\pi}\sigma_{c,i}} exp(-\frac{(x_i-\mu_c,i)^2}{2\sigma^2_{c,i}}) $$
### 西瓜书实例 ###
<img src="/images/xishi1.png" width="640"/>
<img src="/images/xishi2.png" width="640"/>
<img src="/images/xishi3.png" width="640"/>
### 统计学习实例 ###
<img src="/images/tongshi1.png" width="640"/>
<img src="/images/tongshi2.png" width="640"/>
### 拉普拉斯修正 ###
用极大似然估计可能会出现所要估计的概率值为0的情况，这回影响到后验概率的计算结果，是分类产生偏差。在估计概率时通常进行‘平滑’，常用拉普拉斯修正。具体来说，令N表示训练集D中可能的类别数，Ni表示第i个属性可能的取值数，则
$$ \hat P(c)=\frac{|D_c|+1}{|D|+N} $$
$$ \hat P(x_i|c)=\frac{|D_{c,x_i}|+1}{|D_c|+N_i} $$
